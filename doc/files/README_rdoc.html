<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>File: README.rdoc [Robotstxt]</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Script-Type" content="text/javascript" />
  <link rel="stylesheet" href=".././rdoc-style.css" type="text/css" media="screen" />
  <script type="text/javascript">
  // <![CDATA[

  function popupCode( url ) {
    window.open(url, "Code", "resizable=yes,scrollbars=yes,toolbar=no,status=no,height=150,width=400")
  }

  function toggleCode( id ) {
    if ( document.getElementById )
      elem = document.getElementById( id );
    else if ( document.all )
      elem = eval( "document.all." + id );
    else
      return false;

    elemStyle = elem.style;

    if ( elemStyle.display != "block" ) {
      elemStyle.display = "block"
    } else {
      elemStyle.display = "none"
    }

    return true;
  }

  // Make codeblocks hidden by default
  document.writeln( "<style type=\"text/css\">div.method-source-code { display: none }<\/style>" )

  // ]]>
  </script>

</head>
<body>


  <div id="fileHeader">
    <h1>README.rdoc</h1>
    <table class="header-table">
    <tr class="top-aligned-row">
      <td><strong>Path:</strong></td>
      <td>README.rdoc

      </td>
    </tr>
    <tr class="top-aligned-row">
      <td><strong>Last Update:</strong></td>
      <td>2009-12-06 16:03:41 +0100</td>
    </tr>
    </table>
  </div>
  <!-- banner header -->

  <div id="bodyContent">

  <div id="contextContent">

    <div id="description">
      <h1><a href="../classes/Robotstxt.html">Robotstxt</a></h1>
<p>
<a href="../classes/Robotstxt.html">Robotstxt</a> is an Ruby robots.txt
file parser.
</p>
<p>
<a href="../classes/Robotstxt.html">Robotstxt</a> Parser allows you to the
check the accessibility of URLs and get other data.
</p>
<p>
Full support for the robots.txt RFC, wildcards and Sitemap: rules.
</p>
<h2>Features</h2>
<ul>
<li>Check if the URL is allowed to be crawled from your Robot

</li>
<li>Analyze the robots.txt file to return an Array containing the list of XML
Sitemaps URLs

</li>
</ul>
<h2>Requirements</h2>
<ul>
<li>Ruby >= 1.8.7

</li>
</ul>
<h2>Installation</h2>
<p>
This library is intended to be installed via the <a
href="http://rubyforge.org/projects/rubygems/">RubyGems</a> system.
</p>
<pre>
  $ gem install robotstxt
</pre>
<p>
You might need administrator privileges on your system to install it.
</p>
<h2>Author</h2>
<table>
<tr><td valign="top">Author:</td><td><a href="http://www.simonerinzivillo.it/">Simone Rinzivillo</a>
<srinzivillo@gmail.com>

</td></tr>
</table>
<h2>Resources</h2>
<ul>
<li><a href="http://www.simonerinzivillo.it/">Homepage</a>

</li>
</ul>
<h2>License</h2>
<p>
Copyright &#169; 2009 Simone Rinzivillo, <a
href="../classes/Robotstxt.html">Robotstxt</a> is released under the MIT
license.
</p>

    </div>

   </div>


  </div>

    <!-- if includes -->

    <div id="section">




    <!-- if method_list -->




  </div>

<div id="validator-badges">
  <p><small><a href="http://validator.w3.org/check/referer">[Validate]</a></small></p>
</div>

</body>
</html>
